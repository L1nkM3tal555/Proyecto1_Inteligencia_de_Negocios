{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWi3aqi8RUwC"
   },
   "source": [
    "# **Inteligencia de negocios - ISIS3301**\n",
    "\n",
    "# **Proyecto 1 - Analitica de texto**\n",
    "\n",
    "## **Sección 2**\n",
    "## **Grupo 23**\n",
    "*   Rafael Santiago Bastos Russi - *202110792*\n",
    "*   David Santiago Valderrama Herrera - *201910987*\n",
    "*   Jesús Alejandro Dávila Pinchao - *202014263*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEGkkcouQRlK"
   },
   "source": [
    "# **Caso de estudio**\n",
    "\n",
    "La Organización de las Naciones Unidas (ONU) adopta, el 25 de septiembre del año 2015, la\n",
    "Agenda 2030i para el desarrollo sostenible, cuyo fin es reducir la pobreza, garantizar acceso\n",
    "a la salud y educación, buscar igualdad de género y oportunidades, disminuir el impacto\n",
    "ambiental, entre otros. Esta agenda se basa en 17 objetivos de desarrollo sostenibleii (ODS)\n",
    "y 169 metas (derivadas de los diferentes ODS).\n",
    "Dentro del trabajo en conjunto de diferentes entes para alcanzar el cumplimiento de los\n",
    "ODS, muchas entidades tienen como enfoque el seguimiento y la evaluación de las políticas\n",
    "públicas y su impacto a nivel social. Este es el caso del Fondo de Poblaciones de las Naciones\n",
    "Unidas (UNFPAiii) que, junto con entidades públicas y haciendo uso de diferentes\n",
    "herramientas de participación ciudadana, busca identificar problemas y evaluar soluciones\n",
    "actuales, relacionando la información con los diferentes ODS. En este contexto, uno de los\n",
    "procesos que requiere de un mayor esfuerzo es la clasificación de la información textual\n",
    "que es recopilada, ya que es una tarea que consume gran cantidad recursos y para la cual\n",
    "se requiere un experto. Es por esto que, en los últimos años, UNFPA ha venido trabajando,\n",
    "en conjunto con la Universidad de los Andes, en la implementación de diferentes estrategias\n",
    "de clasificación de textos, que les permitan hacer un análisis automatizado de opiniones\n",
    "que representan la voz de los habitantes locales sobre problemáticas de su entorno\n",
    "particular.\n",
    "Para apoyar a UNFPA en este proceso se ha planteado el primer proyecto del curso, cuyo\n",
    "objetivo es desarrollar un modelo de clasificación, con técnicas de aprendizaje\n",
    "automático, que permita relacionar de manera automática un texto según los ODS. Al\n",
    "igual que desarrollar una aplicación que facilite la interacción con el resultado de dicho\n",
    "modelo. El modelo podrá ser utilizado entonces para la interpretación y análisis de la\n",
    "información textual que es recopilada a través de diferentes fuentes por UNFPA en procesos\n",
    "de planeación participativa para el desarrollo a nivel territorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqt3F-z6TypQ"
   },
   "source": [
    "#**Etapa 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RqSJ3hCjcyw"
   },
   "source": [
    "## **1. Importación de librerias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydGK3sOaEwcQ",
    "outputId": "3b19057b-f163-4a93-8e9a-f859f393fe0f"
   },
   "outputs": [],
   "source": [
    "!pip install num2words\n",
    "!pip install inflect\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cb7X0jBzjowM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import re, string, unicodedata\n",
    "\n",
    "import inflect\n",
    "import nltk\n",
    "import spacy\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Versiones anteriores a 1.2 de sklearn: from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from num2words import num2words\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Librerías para la visualización\n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn\n",
    "import seaborn as sns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SsyEOsRJjzBn",
    "outputId": "464ec513-6f81-45f0-b457-47d8dcf35214"
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbyxsMA6algF",
    "outputId": "ad8d1ab7-64c7-4e59-f531-1ad351790b51"
   },
   "outputs": [],
   "source": [
    "!python -m spacy download es_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXTGU_jCkfu-"
   },
   "source": [
    "## **2. Perfilamiento y entendimiento de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dK9eAjU7ko8v"
   },
   "source": [
    "### **2.1. Lectura de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPjl-orSk8XE"
   },
   "outputs": [],
   "source": [
    "data=pd.read_excel('./data/cat_345.xlsx')\n",
    "# Asignación a una nueva variable de los datos leidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLPq975kkwzo"
   },
   "source": [
    "### **2.2. Entendimiento de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "El7nti_enuKv",
    "outputId": "de90389f-6a3d-4abc-901d-abe34a4ba378"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_2yRo6U6oJzp",
    "outputId": "54452f72-3964-4a72-e9b6-7ce3067dd5d5"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPBnrtvYplx1",
    "outputId": "c7c66f46-c105-4bf0-c9e6-3be3d97fa5a0"
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "-FNPfx8ZnMoW",
    "outputId": "4a73a8cc-e8fb-4618-920e-e89c729b5297"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ftylfK_rr35Z",
    "outputId": "3cf2fbec-971a-485b-9c32-1d38d1016c59"
   },
   "outputs": [],
   "source": [
    "pd.value_counts(data['sdg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7Wn-CEqsBlu",
    "outputId": "87870345-370e-49c5-94ee-d8fa8d8ee19d"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6eVVQ_osMnN",
    "outputId": "ed38f136-169f-4224-f463-cb4b9cd166c4"
   },
   "outputs": [],
   "source": [
    "data.duplicated(keep = False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5sacxTjtog-"
   },
   "source": [
    "## **3. Preparación de los datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSGzLf9AOh8I"
   },
   "source": [
    "Se realizaran las siguientes actividades para una adecuada preparación de los datos:\n",
    "\n",
    "\n",
    "\n",
    "*   Limpieza de los datos.\n",
    "*   Tokenización.\n",
    "*   Normalización.\n",
    "\n",
    "Usando las librerias spacy para el procesamiento de las palabras incluyendo su lematización y verificación de números, unicodedata para eliminar caracteres especiales y num2words para convertir numeros en palabras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCzZeDBwPL9_"
   },
   "source": [
    "## **3.1. Limpieza y tokenización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrFsJDagO89Z"
   },
   "outputs": [],
   "source": [
    "data_t = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZ_hVkd5boaB"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ObG5wn6rNOnX"
   },
   "source": [
    "Se carga el modulo para español de spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FIsMfFBcrbg",
    "outputId": "2a5f7da1-2b6f-41e8-baec-e0512b9d7e12"
   },
   "outputs": [],
   "source": [
    "texts = data_t['Textos_espanol']\n",
    "tokens = []\n",
    "\n",
    "stop_words = nlp.Defaults.stop_words  #Stop words en español\n",
    "cont = 0\n",
    "for opinion in texts:\n",
    "  opinionP = opinion.lower() #Se pone el texto en minusculas\n",
    "  opinionP = unicodedata.normalize('NFKD', opinionP).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  #Se quitan caracteres especiales\n",
    "  opinionDoc = nlp(opinionP) #Se crea un doc con npl para procesar el texto\n",
    "  tokensI = []\n",
    "  for word in opinionDoc:\n",
    "    wordP = re.sub(r'[^\\w\\s]', '', word.text) #Remover signos de puntuación\n",
    "    if wordP != '':\n",
    "      if wordP == \"15.7\":\n",
    "           print(wordP)\n",
    "      if word.is_digit:\n",
    "        #print(wordP)\n",
    "\n",
    "        num_word = num2words(wordP, lang='es')\n",
    "        #print(num_word)\n",
    "        tokensI.append(num_word)\n",
    "        if cont == 5:\n",
    "           print(wordP)\n",
    "           print(num_word)\n",
    "\n",
    "      else:\n",
    "        if word.text not in stop_words: #No se tienen en cuenta las stop words\n",
    "            tokensI.append(word.lemma_) #Se toma en cuenta solo el lemma de la palabra\n",
    "  cont+=1\n",
    "  tokens.append(tokensI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zR7gF_1Ke8CA",
    "outputId": "a84bf9d9-0b10-49eb-d809-4ec3866dfc9f"
   },
   "outputs": [],
   "source": [
    "data_t['words'] = pd.Series(tokens, copy=False)\n",
    "data_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t[\"words\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datix = data_t[\"words\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMpTpBT4PF4f"
   },
   "source": [
    "## **3.2. Normalización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_t['words'] = data_t['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t[\"words\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UMo3Nyo9PcFs"
   },
   "outputs": [],
   "source": [
    "X_data, Y_data = data_t['words'], data_t['sdg'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NTcZufUnPgdW"
   },
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(max_features=3000)\n",
    "X_data = tf_idf.fit_transform(X_data)\n",
    "\n",
    "print(X_data.shape)\n",
    "X_data.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKA-AoVJQo0g"
   },
   "source": [
    "Para normalizar se usa un vectorizador TF-IDF, quedando la variable predictora en Y_data y los textos en X_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Modelos de clasificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.1. Primer modelo: Árbol de decisión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. **Modelo de Prueba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las categorías en el conjunto de entrenamiento\n",
    "y_pred_test = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Precisión: {accuracy}')\n",
    "\n",
    "report = classification_report(y_test, y_pred_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera la matriz de confusión\n",
    "cm_test = confusion_matrix(y_test, y_pred_test, labels = clf.classes_)\n",
    "cm_test_norm = confusion_matrix(y_test, y_pred_test, labels = clf.classes_, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se puede visualizar la matriz de confusión\n",
    "#plot_confusion_matrix(arbol, X_test, Y_test)}\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=clf.classes_)\n",
    "disp_test.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "disp_test_norm = ConfusionMatrixDisplay(confusion_matrix=cm_test_norm, display_labels=clf.classes_)\n",
    "disp_test_norm.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. **Modelo de Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir las categorías en el conjunto de entrenamiento\n",
    "y_pred_train = clf.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f'Precisión: {accuracy}')\n",
    "\n",
    "report = classification_report(y_train, y_pred_train)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de Confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se genera la matriz de confusión\n",
    "cm_train = confusion_matrix(y_train, y_pred_train, labels = clf.classes_)\n",
    "cm_train_norm = confusion_matrix(y_train, y_pred_train, labels = clf.classes_, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz de confusión\n",
    "\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=clf.classes_)\n",
    "disp_train.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "disp_train_norm = ConfusionMatrixDisplay(confusion_matrix=cm_train_norm, display_labels=clf.classes_)\n",
    "disp_train_norm.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.2. Segundo modelo: K-Nearest Neighbors (KNN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento del \"modelo\"\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.1. Modelo de Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de predicciones para prueba\n",
    "preds_train = knn_model.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, preds_train)\n",
    "print(f'Precisión: {accuracy}')\n",
    "\n",
    "report = classification_report(y_train, preds_train)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de Confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de la matriz de confusión\n",
    "cm_train = confusion_matrix(y_train, preds_train, labels = knn_model.classes_)\n",
    "cm_train_norm = confusion_matrix(y_train, preds_train, labels = knn_model.classes_, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=knn_model.classes_)\n",
    "disp_train.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "disp_train_norm = ConfusionMatrixDisplay(confusion_matrix=cm_train_norm, display_labels=knn_model.classes_)\n",
    "disp_train_norm.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.2.1. Modelo de Prueba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de predicciones para prueba\n",
    "preds_test = knn_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, preds_test)\n",
    "print(f'Precisión: {accuracy}')\n",
    "\n",
    "report = classification_report(y_test, preds_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de la matriz de confusión\n",
    "cm_test = confusion_matrix(y_test, preds_test, labels = knn_model.classes_)\n",
    "cm_test_norm = confusion_matrix(y_test, preds_test, labels = knn_model.classes_, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=knn_model.classes_)\n",
    "disp_test.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "disp_test_norm = ConfusionMatrixDisplay(confusion_matrix=cm_test_norm, display_labels=knn_model.classes_)\n",
    "disp_test_norm.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4.3. Tercer modelo: TF-IDF con Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = RandomForestClassifier(random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. **Modelo de Entrenamiento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_estimators = tfidf_model.estimators_\n",
    "print(\"Number of trees:\", len(tfidf_estimators))\n",
    "print(\"Trees depth (mean):\", np.mean([tree.get_depth() for tree in tfidf_estimators]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tfidf_predict = tfidf_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_train, y_train_tfidf_predict)\n",
    "print(f'Precisión: {accuracy}')\n",
    "\n",
    "report = classification_report(y_train, y_train_tfidf_predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de Confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de la matriz de confusión\n",
    "cm_train = confusion_matrix(y_train, y_train_tfidf_predict, labels = tfidf_model.classes_)\n",
    "cm_train_norm = confusion_matrix(y_train, y_train_tfidf_predict, labels = tfidf_model.classes_, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=tfidf_model.classes_)\n",
    "disp_train.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "disp_train_norm = ConfusionMatrixDisplay(confusion_matrix=cm_train_norm, display_labels=tfidf_model.classes_)\n",
    "disp_train_norm.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Modelo de Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_estimators = tfidf_model.estimators_\n",
    "print(\"Number of trees:\", len(tfidf_estimators))\n",
    "print(\"Trees depth (mean):\", np.mean([tree.get_depth() for tree in tfidf_estimators]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tfidf_predict = tfidf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_tfidf_predict)\n",
    "print(f'Precisión: {accuracy}')\n",
    "\n",
    "report = classification_report(y_test, y_test_tfidf_predict)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Matriz de Confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación de la matriz de confusión\n",
    "cm_test= confusion_matrix(y_test, y_test_tfidf_predict, labels = tfidf_model.classes_)\n",
    "cm_test_norm = confusion_matrix(y_test, y_test_tfidf_predict, labels = tfidf_model.classes_, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización de la matriz\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=tfidf_model.classes_)\n",
    "disp_test.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "disp_test_norm = ConfusionMatrixDisplay(confusion_matrix=cm_test_norm, display_labels=tfidf_model.classes_)\n",
    "disp_test_norm.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Selección del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [4, 8, 12, 16, 20, 24, 28, 32, 36, 40],\n",
    "    'min_samples_split': [2, 3, 4, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_model = GridSearchCV(clf, param_grid, scoring = ['precision', 'recall', 'f1'], refit = 'f1', cv = 10, n_jobs = -1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df = pd.DataFrame(grid_tree_model.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data = pd.read_excel('./data/SinEtiquetatest_cat_345.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagging(data):\n",
    "    data_t = data.copy()\n",
    "    global nlp\n",
    "    texts = data_t['Textos_espanol']\n",
    "    tokens = []\n",
    "\n",
    "    stop_words = nlp.Defaults.stop_words  #Stop words en español\n",
    "    cont = 0\n",
    "    for opinion in texts:\n",
    "        opinionP = opinion.lower() #Se pone el texto en minusculas\n",
    "        opinionP = unicodedata.normalize('NFKD', opinionP).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        #Se quitan caracteres especiales\n",
    "        opinionDoc = nlp(opinionP) #Se crea un doc con npl para procesar el texto\n",
    "        tokensI = []\n",
    "        for word in opinionDoc:\n",
    "            wordP = re.sub(r'[^\\w\\s]', '', word.text) #Remover signos de puntuación\n",
    "            if wordP != '':\n",
    "                if wordP == \"15.7\":\n",
    "                    print(wordP)\n",
    "                if word.is_digit:\n",
    "\n",
    "                    num_word = num2words(wordP, lang='es')\n",
    "                    tokensI.append(num_word)\n",
    "\n",
    "                else:\n",
    "                    if word.text not in stop_words: #No se tienen en cuenta las stop words\n",
    "                        tokensI.append(word.lemma_) #Se toma en cuenta solo el lemma de la palabra\n",
    "        cont+=1\n",
    "        tokens.append(tokensI)\n",
    "    data_t['words'] = pd.Series(tokens, copy=False)\n",
    "    data_t['words'] = data_t['words'].apply(lambda x: ' '.join(map(str, x)))\n",
    "    global unlabeled_X_data\n",
    "    unlabeled_X_data = data_t['words']\n",
    "    unlabeled_X_data = tf_idf.fit_transform(unlabeled_X_data)\n",
    "    tfidf_model.predict(unlabeled_X_data)\n",
    "    columns_to_drop = ['predicted_labels', 'predicted_sdg']\n",
    "    data_x = data.drop(columns_to_drop, axis=1)\n",
    "    data_x.to_csv('./data/labeled_unlabeled_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
